---
title: "Minimum Wage by State from 1968 to 2020"
author: "Joseph Lisle"
date: "December 2020"
---

# Loading general packages
```{r}
install.packages("tidyverse")
library(tidyverse)
```

# Loading in historical minimum wage data by state
```{r, message=FALSE, warning=FALLSE}
# # Downloading historical minimum wage data
# # Code taken from this website: https://stackoverflow.com/questions/1395528/scraping-html-tables-into-r-data-frames-using-the-xml-package
# 
# install.packages("XML")
# install.packages("RCurl")
# install.packages("rlist")
# 
# library(XML)
# library(RCurl)
# library(rlist)
# 
# # Getting URL and loading in table
# RCurl::curlVersion()$ssl_version
# theurl <- getURL("https://www.dol.gov/agencies/whd/state/minimum-wage/history", ssl.verifypeer = FALSE, sslversion="CURL_SSLVERSION_SSLv4")
# tables <- readHTMLTable(theurl)
# tables <- list.clean(tables, fun = is.null, recursive = FALSE)
# n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
# 
# # Creating data frames from each table on the page
# Table1 <- as.data.frame(tables[1])
# Table2 <- as.data.frame(tables[2])
# Table3 <- as.data.frame(tables[3])
# Table4 <- as.data.frame(tables[4])
# Table5 <- as.data.frame(tables[5])

# The code was no longer working for me and I was unable to find a solution in an appropriate amount of time, so I elected to simply copy and paste the tables into Microsoft Excel and upload them here
# Note that I also found the minimum wage by state for 2020 and appended it to the final table. The website where I found the information is: https://www.ncsl.org/research/labor-and-employment/state-minimum-wage-chart.aspx?
Table1 <- read.csv("Table1.csv")
Table2 <- read.csv("Table2.csv")
Table3 <- read.csv("Table3.csv")
Table4 <- read.csv("Table4.csv")
Table5 <- read.csv("Table5.csv")

# Let's review the tables to see what needs to be done to clean them
str(Table1)
str(Table2)
str(Table3)
str(Table4)
str(Table5)
```

# Data Cleaning
## Initial cleaning
```{r}
# Looks like the data is fairly clean! Let's fix the variable names and combine the tables.

# Fixing the variable names
names(Table1) <- c("State", "1968", "1970", "1972", "1976", "1979", "1980", "1981")
names(Table2) <- c("State", "1988", "1991", "1992", "1994", "1996", "1997", "1998")
names(Table3) <- c("State", "2000", "2001", "2002", "2003", "2004", "2005", "2006")
names(Table4) <- c("State", "2007", "2008", "2009", "2010", "2011", "2012", "2013")
names(Table5) <- c("State", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

# As I won't need the state for each table after the first, let's remove them.
Table2$State <- NULL
Table3$State <- NULL
Table4$State <- NULL
Table5$State <- NULL

# Creating one data frame from all of the tables
Data <- cbind(Table1, Table2)
Data <- cbind(Data, Table3)
Data <- cbind(Data, Table4)
Data <- cbind(Data, Table5)

# Looking good!
Data
```

## Gathering Data
```{r, warning=FALSE}
# Gathering data frame
Data <- gather(Data, Year, Table_Data, -State)
str(Data)
```

## Cleaning up "Year"
```{r}
# Cleaning "Year" data
Data$Year <- as.numeric(Data$Year)
```

## Adding the footnotes to a new column for easy visualization later one
```{r}
# Moving the footnotes to a new column
# This detects if there are and "[" or "("in the Table_Data column, then moves anything past that character to the Footnote column
Data$Footnote <- as.factor(
  ifelse(str_detect(Data$Table_Data, '\\(') == T,
           substr(Data$Table_Data, regexpr('\\(', Data$Table_Data), str_length(Data$Table_Data)),
  ifelse(str_detect(Data$Table_Data, "\\[") == T,
           substr(Data$Table_Data, regexpr("\\[", Data$Table_Data), str_length(Data$Table_Data)),
         "")))

# ...and cleaning up the "(g,j)" and NA fiasco
Data$Footnote <- as.factor(
  ifelse(Data$Footnote == "(g, j)" |
         Data$Footnote == "(g,,j)" |
         Data$Footnote == "(g,j)",
         "(g, j)",
  ifelse(str_detect(Data$Footnote, "e"),
         "(e)",
  ifelse(str_detect(Data$Footnote, "c"),
         "[c]",
         as.character(Data$Footnote)))))

Data$Footnote[is.na(Data$Footnote)] <- ""

# Looks good to go!
table(Data$Footnote, useNA = "ifany") 
```

## Cleaning up the hourly wage data
```{r, warning=FALSE}
# The hourly wage data is really messy! Let's clean this up...
# Here's a function that will do the trick. As there are some ranges and multiple minimum wages for some years and states, I have two functions that will pull the higher or lower of the pair.
High.Wage.Clean <- function(x){
  x <- ifelse(str_detect(x, '\\(') == T, # Removing footnotes - they have their own column now
              substr(x, 0, (regexpr('\\(', x)-1)),
       ifelse(str_detect(x, '\\[') == T,
              substr(x, 0, (regexpr('\\[', x)-1)),
              as.character(x)))
  x <- str_trim(x, side="both") # Removing extra spaces on outsides
  x <- str_replace_all(x, " ", "") # Removing extra spaces within
  x <- str_replace_all(x, "\\$", "") # Removing $s
  x <- str_replace(x, "\\`", "") # Removing `s
  x <- str_replace(x, "\\&", "-") # Making all the ranges uniform for easy handling
  x <- substr(x, (regexpr('-', x)+1), str_length(x)) # Keeping only the higher value
  x <- ifelse(str_detect(x, "wk") == T,  # detecting if it's a weekly/daily minimum and convering to hourly wage at 40 hrs/wk
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/40,
       ifelse(str_detect(x, "day") == T,
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/8,
       ifelse(x == "...", 0, 
              as.character(x))))
  x <- ifelse(x == "4..65", 4.65, as.numeric(x)) # fixing the double periods
  return(x)
}

Low.Wage.Clean <- function(x){
  x <- ifelse(str_detect(x, '\\(') == T, # Removing footnotes - they have their own column now
              substr(x, 0, (regexpr('\\(', x)-1)),
       ifelse(str_detect(x, '\\[') == T,
              substr(x, 0, (regexpr('\\[', x)-1)),
              as.character(x)))
  x <- str_trim(x, side="both") # Removing extra spaces on outsides
  x <- str_replace_all(x, " ", "") # Removing extra spaces within
  x <- str_replace_all(x, "\\$", "") # Removing $s
  x <- str_replace(x, "\\`", "") # Removing `s
  x <- str_replace(x, "\\&", "-") # Making all the ranges uniform for easy handling
  x <- ifelse(str_detect(x, "-") == T & str_detect(x, "\\/") == T,  # Keeping only the lower value
              paste(substr(x, 1, (regexpr('-', x)-1)),substr(x, (regexpr('\\/', x)),str_length(x))),
       ifelse(str_detect(x, "-") == T,
              substr(x, 1, (regexpr('-', x)-1)),
              as.character(x)))
  x <- ifelse(str_detect(x, "wk") == T,  # detecting if it's a weekly/daily minimum and convering to hourly wage at 40 hrs/wk
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/40,
       ifelse(str_detect(x, "day") == T,
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/8,
       ifelse(x == "...", 0, 
              as.character(x))))
  x <- ifelse(x == "4..65", 4.65, as.numeric(x)) # fixing the double periods
  return(x)
}

# Now to apply it to the data...
Table_Data <- as.list(Data$Table_Data)

High_Value <- lapply(Table_Data, High.Wage.Clean) # Applying high value and low value extraction functions
Low_Value  <- lapply(Table_Data, Low.Wage.Clean)

High_Value <- as.data.frame(High_Value) # Preparing the new values for import into Data
Low_Value  <- as.data.frame(Low_Value)

High_Value <- gather(High_Value, Random, High.Value) # Further prep. Need to gather the values
Low_Value  <- gather(Low_Value, Random, Low.Value)

# Make sure it's all set...
table(High_Value$High.Value, useNA="ifany")
table(Low_Value$Low.Value, useNA="ifany")

# Add to main dataset
Data$High.Value <- High_Value$High.Value
Data$Low.Value <- Low_Value$Low.Value

# Spot to make sure that the values still make sense
Data %>%
  select(High.Value, Table_Data)

Data %>%
  select(Low.Value, Table_Data)
```

## Adding Missing Values
```{r}
# Because no new legislation took effect in some years, there was no data for those years in the table I scraped earlier in this report
# Although there was no data in the table for these years, it's important that we have the data in the data set as the minimum wage decreased in value during those periods. It will also make the visualizations feel more complete.

# There are hardly any missing years, so I'm just going to create an additional dataset for them by hand (it's faster for right now!)
MissingYears <- as.data.frame(c("1969", "1971", "1973", "1974", "1975", "1977", "1978", "1982", "1983", "1984", "1985", "1986", "1987", "1989", "1990", "1993", "1995", "1999"))
MissingYears <- rename(MissingYears, Years = `c("1969", "1971", "1973", "1974", "1975", "1977", "1978", "1982", "1983", "1984", "1985", "1986", "1987", "1989", "1990", "1993", "1995", "1999")`)
MissingYearsList <- c("1969", "1971", "1973", "1974", "1975", "1977", "1978", "1982", "1983", "1984", "1985", "1986", "1987", "1989", "1990", "1993", "1995", "1999")

# Creating a dataset for all the missing values. I only need the first 990 (18 years by 55 "states") rows
States <- Data$State
MissingYears <- merge(MissingYears, States)
MissingYears <- MissingYears[1:990,1:2]
str(MissingYears)

# Adding extra columns for an rbind with Data
MissingYears <- MissingYears %>%
  rename(State = y, Year = Years) %>%
  mutate(Table_Data = "", Footnote = "", High.Value = "", Low.Value = "")

# Binding rows and sorting so that I can add in the missing data in a moment
Data <- rbind(Data, MissingYears)
Data <- Data %>%
  arrange(State, Year)

# Adding in minimum wage, footnotes, and cleaned Value to the missing years dataset
# Here's where I got the base of the formula: https://stackoverflow.com/questions/13155609/returning-above-and-below-rows-of-specific-rows-in-r-dataframe
# Original Minimum Wage Value
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$Table_Data_Fixed[i] <- Data$Table_Data[i]
    } else {
      Data$Table_Data_Fixed[i] <- Data$Table_Data_Fixed[(i-1)]
    }
}

# Footnotes
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$Footnote_Fixed[i] <- as.character(Data$Footnote[i])
    } else {
      Data$Footnote_Fixed[i] <- as.character(Data$Footnote_Fixed[(i-1)])
    }
}

# Cleaned values
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$High.Value_Fixed[i] <- Data$High.Value[i]
    } else {
      Data$High.Value_Fixed[i] <- Data$High.Value_Fixed[(i-1)]
    }
}
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$Low.Value_Fixed[i] <- Data$Low.Value[i]
    } else {
      Data$Low.Value_Fixed[i] <- Data$Low.Value_Fixed[(i-1)]
    }
}

# Double checking to make sure everything looks as expected
# Table_Data
Data %>%
  select(Year, Table_Data, Table_Data_Fixed)

# Footnote
Data %>%
  select(Year, Footnote, Footnote_Fixed)

# Value
Data %>%
  select(Year, High.Value, High.Value_Fixed)

Data %>%
  select(Year, Low.Value, Low.Value_Fixed)

# Replacing Old Columns
Data <- Data %>%
  select(State, Year, Table_Data_Fixed, Footnote_Fixed, High.Value_Fixed, Low.Value_Fixed) %>%
  rename(Table_Data = Table_Data_Fixed, Footnote = Footnote_Fixed, High.Value = High.Value_Fixed, Low.Value = Low.Value_Fixed)
```

## Calculating 2018 dollars
```{r}
# It's a fairly simple calculation to calculate 2018 dollars from any point in time!
# Just create an equation (x/y) * b, with the x being the average Consumer Price Index (CPI) from 2018 and y being the average CPI from the other year in the denominator. B is equal to the dollar amount in y's year

# First, I need to add the CPI for each year. Luckily, I can easily get this from the [Bureau of Labor Statistics](https://www.bls.gov/cpi/home.htm). I used the "All items in U.S. city average, all urban consumers, not seasonally adjusted" dataset. The value for 2020 is simply an average of each month except December.
CPI <- read.csv("CPI 1913-2020.csv")

# Now I'll add the CPI Average to my dataset for easy calculation
Data <- merge(x = Data, y = CPI, by = "Year", all.y = F, all.x = T)
Data %>% rename(CPI.Average = Annual)

# Now calculating 2018 dollars! The CPI for 2020, Jan-Nov is 258.66
Data$High.2020 <- round((258.66/Data$CPI.Average) * as.numeric(Data$High.Value), 2)
Data$Low.2020 <- round((258.66/Data$CPI.Average) * as.numeric(Data$Low.Value), 2)
```

# Federal Minimum Wage
```{r}
# The federal minimum wage is mixed in with the states for right now, but that shouldn't be the case. I'm going to create a separate column for the data.
# Here's the federal minimum wage
Federal.Data <- Data %>% filter(str_detect(State, "Federal"))
Federal.Data <- Federal.Data %>% select(Year, Federal.Minimum.Wage = Low.Value, Federal.Minimum.Wage.2020 = Low.2020)

# Now let's merge it in with the regular table and remove the federal data from the real table
Data <- merge(x = Data, y = Federal.Data, by = "Year", all.y = F, all.x = T)
Data <- Data %>% filter(str_detect(State, "Federal")==F)
```

# General Cleaning
``` {r}
# As it stands, the dataset is pretty messy. There are some columns that provide superfluous information and others that provide important information but the titles of the columns hide that fact. Let's make this dataset look nicer.

# First, let's address the NA values
Data$Table_Data[is.na(Data$Table_Data)] <- "..."
Data$High.Value[is.na(Data$High.Value)] <- 0
Data$Low.Value[is.na(Data$Low.Value)] <- 0

# Next, let's add some data so everything makes a bit more sense
Data <- Data %>% mutate(Effective.Minimum.Wage = if_else(Low.Value < Federal.Minimum.Wage, Federal.Minimum.Wage, Low.Value), Effective.Minimum.Wage.2020 = round((258.66/CPI.Average) * as.numeric(Effective.Minimum.Wage), 2))
str(Data)

# Finally, let's rename and move the columns to make them a bit more accessible
Data <- Data %>% select(Year, State, State.Minimum.Wage = Low.Value, State.Minimum.Wage.2020.Dollars = Low.Value, Federal.Minimum.Wage, Federal.Minimum.Wage.2020.Dollars = Federal.Minimum.Wage.2020, Effective.Minimum.Wage, Effective.Minimum.Wage.2020.Dollars = Effective.Minimum.Wage.2020, CPI.Average, Department.Of.Labor.Uncleaned.Data = Table_Data, Department.Of.Labor.Cleaned.Low.Value = Low.Value, Department.Of.Labor.Cleaned.Low.Value.2020.Dollars = Low.2020, Department.Of.Labor.Cleaned.High.Value = High.Value, Department.Of.Labor.Cleaned.High.Value.2020.Dollars = High.2020, Footnote)
```

# Saving Data
```{r}
# The data is ready! Going to make it a bit cleaner to read...
Data <- Data %>%
  arrange(Year, State)

# Writing to CSV
write.csv(Data, file="Minimum Wage Data.csv", row.names = FALSE)
```
